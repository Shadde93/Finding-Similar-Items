{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadman Ahmed, Oguzhan Ugur\n",
    "\n",
    "## Notice\n",
    "You run the code by running all the cells, the last three cells prints the results\n",
    "\n",
    "## Finding Similar Items: Textually Similar Documents  \n",
    "\n",
    "### Problem Formulation\n",
    " \n",
    "In this assignment, we were instructed to implement an application that finds similarities in documents based on Jacard similarity using shingling, minhashing, and locality-sensitive hashing. The lab descriptions instructs us to create five classes in order to construct this similarity detector:\n",
    "- Class 1: Shingling\n",
    "- Class 2: JacardSimilarity\n",
    "- Class 3: Minhashing\n",
    "- Class 4: CompareSignatures\n",
    "- Class 5: LSH\n",
    "\n",
    "### Data\n",
    "The data used in this assignment were 10 different text documents. These documents are stored in the directory named \"Data\" and was taken from UCI- opinosis Opinion/Review. \n",
    "\n",
    "### Shingling\n",
    "K-shingling is a method that divides the document into several parts, in other words it converts documents into sets(shingles). We created a Shingle class that has 3 functions:<br>\n",
    "- First _FileRead_, that reads the file, filters the punctuations and returns the text without punctuations.<br>\n",
    "- Second _CreateShingles_, that creates the shingles and returns a list with all of the shingles for respective document. Consider that it is possible to choose the shingle size by changing __k__.<br>\n",
    "- Third _CreateHash_, that hashes the shingles that was stored in a list and returns a list with hash values corresponding to respective shingles and the name of the document. The hashlib library (md5) was used in order to create the hash values. The name of the document is returned because we wanted to store all the hashed values in a dictionary with the name of the document as key value. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import string \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Shinling:\n",
    "    #k- number of shingle\n",
    "    #doc- name of the document\n",
    "    def __init__(self, doc, k):\n",
    "        self.k = k\n",
    "        self.doc = doc\n",
    "        \n",
    "    #Reads the file\n",
    "    def FileRead(self):\n",
    "        \n",
    "        with open(self.doc, \"r\") as file: \n",
    "            text = file.read()\n",
    "            cleanText = \"\"\n",
    "            for character in text:\n",
    "                if character not in string.punctuation:\n",
    "                    cleanText = cleanText + character\n",
    "        return (cleanText)\n",
    "    \n",
    "    #Creates shingles of the cleaned text(text without punctuation)\n",
    "    def CreateShingles(self):\n",
    "        text = self.FileRead()\n",
    "        \n",
    "        shingle_list = []\n",
    "        for index in range(len(text) - self.k + 1):\n",
    "            shingle = text[index:index + self.k]\n",
    "            shingle_list.append(shingle)\n",
    "        shingle_list = [x.replace('\\n', '') for x in shingle_list]\n",
    "        shingle_list = set(shingle_list)\n",
    "        \n",
    "        return(shingle_list)\n",
    "    \n",
    "    #Creates Hash values for each shingle\n",
    "    def CreateHash(self):\n",
    "        shingle_list = self.CreateShingles()\n",
    "        \n",
    "        shingles_in_document = set()\n",
    "        for shingles in shingle_list:\n",
    "            hashvalue = hashlib.md5(shingles.encode())\n",
    "            shingles_in_document.add(hashvalue.hexdigest())   \n",
    "        return(shingles_in_document,self.doc)\n",
    "        \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity\n",
    "Jaccard similarity is a distance measure that can be used to show the similarity and diversity of two sets. In our case this method was used in order to determine the similarity between the shingle sets for each document. The Jaccard similarity score is greater for small shingle sizes, on the other hand, large shingle sizes corresponds to smaller jaccard similarity scores, because the documents we use are different. The Jaccard similarity is computed by taking the intersection between two sets and dividing it by the union of these sets. <br>\n",
    "<br>\n",
    "The Jaccard_Similarity Class consist of one function, \"jaccard\\_similarity\" , that returns the similarity score after calculating the math of the two shingle sets. This function takes _\"document\"_ and _\"name_doc\"_ as input arguments. _document_ is a dictionary that consists of hashed values and corresponding names of each document with the document name as key. The variable name_doc is a list with the names of the documents. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jacard_Similarity:\n",
    "    # documant - is a dictionary, with keys as document names \n",
    "    #            and values as hash values of the shingles\n",
    "    # name_doc - is the name of the documents\n",
    "    def jacard_similarity(self,document,name_doc):\n",
    "\n",
    "        similarity_score = {}\n",
    "        for i in range(len(document)):\n",
    "            shingle_set1= document[name_doc[i]]\n",
    "            for j in range(i+1,len(document)): \n",
    "                shingle_set2 = document[name_doc[j]]\n",
    "                intersection = len(shingle_set1.intersection(shingle_set2))\n",
    "                union = (len(shingle_set1)+len(shingle_set2))-intersection\n",
    "                score = intersection/union\n",
    "                name = name_doc[i]+ \"  vs  \" + name_doc[j]\n",
    "                similarity_score[name] = score\n",
    "                \n",
    "        return(similarity_score)\n",
    " \n",
    " \n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minhashing\n",
    "\n",
    "MinHasing is a method that quickly estimates how similar two sets are. The main idea is to use a charesteristic matrix that consists of zeros and ones. In our case, the rows of the charesteristic matrix  represents shingles and the columns represents the documents. If a shingle appears to be in a document, then the column representing the document will have 1 on the row that represents the shingle and 0 the other way around. This matrix will then be compressed to a signature matrix by using random permuation with hash functions. This signature matrix will then be used in order to determine the similarity between the documents(columns). The number of rows of the signature matrix, will correspond to the number of hash functions. The signature matrix consists of the smallest hashvalue received by the hashfunction for each index of the charesteristic matrix. \n",
    "\n",
    "The minHash Class consist of four functions, _\"createCharMatrix\"_, _\"hashFunction\"_, _\"SignatrueMatrix\"_. <br> \n",
    "- First, The createCharMatrix_ creates the charesteristic matrix by comparing the shingles in the universal set with the single set for each document. The Universal set, is a set with shingles from all of the documents.<br>\n",
    "- Second, The _hashFunction_ returns a list of hash functions with random constants, the hashfunction is equal to ax+b % c where a and b are chosen randomly with the condidtion to be less than the variable maxShingle. And c is a primenumber slightly above the maxShingle number. \n",
    "- Third, The _SignatureMatrix_ creates the signature matrix by using the hash functions and the charesteristic matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minHash:\n",
    "    def __init__(self,doc_hashed_shingle,UniversalSet,numberOfHashFunction):\n",
    "        self.doc_hashed_shingle = doc_hashed_shingle\n",
    "        self.UniversalSet = UniversalSet\n",
    "        self.numberOfHashFunction = numberOfHashFunction\n",
    "    \n",
    "    def createCharMatrix(self):\n",
    "        charact_Matrix = np.zeros((len(self.UniversalSet),len(self.doc_hashed_shingle)))\n",
    "\n",
    "        for index_i,i in enumerate(self.UniversalSet):\n",
    "            for index_j,j in enumerate(self.doc_hashed_shingle):\n",
    "                if i in self.doc_hashed_shingle[j]:\n",
    "                     charact_Matrix[index_i,index_j] = 1\n",
    "                else:\n",
    "                    charact_Matrix[index_i,index_j] = 0\n",
    "        return (charact_Matrix)\n",
    "        \n",
    "    def hashFunction(self,seed = 31):\n",
    "        maxShingle = 4294967295\n",
    "        \n",
    "        c = 4294967311\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        a = np.random.randint(0,maxShingle,self.numberOfHashFunction, dtype = \"int64\")\n",
    "        b = np.random.randint(0,maxShingle,self.numberOfHashFunction, dtype = \"int64\")\n",
    "        \n",
    "        hashFunctionList = []\n",
    "        for i in range(self.numberOfHashFunction):\n",
    "            h = lambda x, j=i: (a[j]*x + b[j])%c\n",
    "            hashFunctionList.append(h)\n",
    "        \n",
    "        return (hashFunctionList)\n",
    "    \n",
    "    def SignatureMatrix(self):\n",
    "        hashFunctions = self.hashFunction()\n",
    "        CharMatrix = self.createCharMatrix()\n",
    "        \n",
    "        signMatrix = np.full((len(hashFunctions),len(self.doc_hashed_shingle)),np.inf)\n",
    "        \n",
    "        for i in range(0,len(self.UniversalSet)):\n",
    "            hash_f = []\n",
    "            for hashfunction in hashFunctions:\n",
    "                hash_1 = hashfunction(i)\n",
    "                hash_f.append(hash_1)\n",
    "            for j in range(0,len(self.doc_hashed_shingle)):\n",
    "                if(CharMatrix[i,j]==1):\n",
    "                    for hf_Index,hashValue in enumerate(hash_f):\n",
    "                        if(hashValue < signMatrix[hf_Index,j]):\n",
    "                            signMatrix[hf_Index,j] = hashValue\n",
    "        return (signMatrix)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of Signatures\n",
    "\n",
    "The similarity of signatures is the fraction of the minhash function(rows) in which they agree. The expected similarity of two signatures equals the Jaccard similarity of the columns or the sets that the signatures represent.\n",
    "\n",
    "The class CompareSignatures consist of one function, \"similarity\\_of\\_sing\". This function returns the similarity score of the signatures. The similarity score between the signatures was determined by comparing 2 columns at a time. For each similarity, +1 was added to a variable named _score_, the total score was then divided by the total number of rows.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareSignatures:\n",
    "    \n",
    "    def similarity_of_sign(self, signMatrix, nameList):\n",
    "        \n",
    "        similarity_score = {}\n",
    "        for i in range(signMatrix.shape[1]):\n",
    "            c1= signMatrix[:,i]\n",
    "            for k in range(i+1, signMatrix.shape[1]):\n",
    "                score = 0\n",
    "                c2= signMatrix[:,k]\n",
    "                for j in range(signMatrix.shape[0]):\n",
    "                    if c1[j] == c2[j]:\n",
    "                        score = score + 1\n",
    "        \n",
    "                \n",
    "                name = nameList[i]+ \"  vs  \" + nameList[k]\n",
    "                similarity_score[name] = score/signMatrix.shape[0]\n",
    "                \n",
    "        return(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH\n",
    "\n",
    "Local sensitive hashing is a method that reduces the complexity by introducing candidate pairs. It basically reduces the dimensionality of high-dimensional data. The LSH maps similar items to buckets by hashing these items. This mapping is conducted by using the signature matrix. The number of buckets is equal to the number of Bands. Bands are partitions of the signature matrix. The columns of these bands are then hashed in order to find similarities between the columns of the bands. If there is any similarity then they are stored in a bucket. The similarity score is then computed as we did before but only for the candidate pairs. \n",
    "\n",
    "The class LSH consist of four functions,<br>\n",
    "- First, The _hashToBuckets_ function returns the buckets with the hashed columns. We chose to map all columns of the bands into the buckets, so we didn't store the similar columns at this stage. \n",
    "- Second, The _CandidatePairs_ function returns a dictionary with the candidate pairs (have same hash value) for each bucket. So, we chose to filter out the non pairs after we mapped all of the hashed columns into the buckets. \n",
    "- Third, The _SimilarityScore_ function returns a dictionary with the scores for the different columns(documents). The key in this dictionary corresponds to the names of the compared documents and the value is the similarity score. \n",
    "- Fourth, The _SimilarDocuments_ function introduces a threshold that filters out the scores that are underneath the threshold and returns a dictionary with the scores above it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    \n",
    "    def __init__(self, signMatrix, r):\n",
    "        self.signMatrix = signMatrix\n",
    "        self.r = r\n",
    "        \n",
    "        \n",
    "    def hashToBuckets(self):\n",
    "        hashed_buckets = {}\n",
    "        sign_matrix = self.signMatrix\n",
    "        for i in range(int(sign_matrix.shape[0]/self.r)):\n",
    "            hashed_bucket = {}\n",
    "            band = sign_matrix [i*self.r:i*self.r+self.r]\n",
    "            for j in range(band.shape[1]):\n",
    "                colband = str(band[:,j])\n",
    "                hashvalue = hashlib.md5(colband.encode())\n",
    "                hashValue = hashvalue.hexdigest()\n",
    "                hashed_bucket[j] = hashValue\n",
    "            hashed_buckets[\"bucket \" + str(i)] = hashed_bucket\n",
    "        return(hashed_buckets)\n",
    "    \n",
    "    def CandidatePairs(self):\n",
    "        hashed_buckets = self.hashToBuckets()\n",
    "        pairFound = {}\n",
    "\n",
    "        for index, key in enumerate(hashed_buckets):\n",
    "            sort_pairs = {}\n",
    "            hashed_values = hashed_buckets[key]\n",
    "            for k,v in hashed_values.items():\n",
    "                sort_pairs.setdefault(v, []).append(k)\n",
    "            for i,j in sort_pairs.items():\n",
    "                if len(j)>1:\n",
    "                    pairFound[\"Bucket \" + str(index)]= j\n",
    "                else:\n",
    "                    pairFound[\"Bucket \" + str(index)]= None           \n",
    "        return(pairFound) \n",
    "  \n",
    "\n",
    "    def SimilarityScore(self):\n",
    "        candidatePairs = self.CandidatePairs()\n",
    "        SimilarityScore = {}\n",
    "        signature_matrix = self.signMatrix\n",
    "        for i,j in candidatePairs.items():\n",
    "            if j != None:\n",
    "                for l in range(len(j)):\n",
    "                    c1 = signature_matrix[:,j[l]]\n",
    "                    for m in range(l+1, len(j)):\n",
    "                        c2 = signature_matrix[:,j[m]]\n",
    "                        score = 0\n",
    "                        for k in range(len(c1)):\n",
    "                            if c1[k] == c2[k]:\n",
    "                                score = score + 1\n",
    "                        SimilarityScore[(j[l],j[m])]= score/len(c1) \n",
    "        return(SimilarityScore)\n",
    "    \n",
    "    \n",
    "    def SimilarDocuments(self,namesofDocument, threshold):\n",
    "        similarity_score = self.SimilarityScore()\n",
    "        score_of_pairs = {}\n",
    "        for i,j in similarity_score.items():    \n",
    "            if j >= threshold:\n",
    "                score_of_pairs[namesofDocument[i[0]] + \" vs \" + namesofDocument[i[1]]] = j   \n",
    "        \n",
    "        return(score_of_pairs)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of Jacard similarity for shingles\n",
    "\n",
    "You can run the code by pressing run or ctrl+enter. <br> You can change the shingle size by changing the variable __k__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents                                                                                           Score     \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/bathroom_bestwestern_hotel_sfo.txt.data       0.62      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/battery-life_ipod_nano_8gb.txt.data           0.61      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data          0.52      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/comfort_honda_accord_2008.txt.data            0.59      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data            0.61      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data      0.71      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data         0.65      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data        0.65      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                    0.63      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/battery-life_ipod_nano_8gb.txt.data          0.59      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data         0.50      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/comfort_honda_accord_2008.txt.data           0.59      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data           0.66      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data     0.66      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data        0.64      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data       0.64      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/features_windows7.txt.data                   0.64      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data             0.49      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/comfort_honda_accord_2008.txt.data               0.57      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data               0.59      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data         0.58      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data            0.59      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data           0.58      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/features_windows7.txt.data                       0.58      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/comfort_honda_accord_2008.txt.data              0.58      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data              0.55      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data        0.57      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data           0.51      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data          0.53      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/features_windows7.txt.data                      0.52      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data                0.69      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data          0.63      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data             0.58      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data            0.60      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/features_windows7.txt.data                        0.58      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data          0.65      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data             0.62      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data            0.65      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/features_windows7.txt.data                        0.63      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data       0.69      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data      0.68      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                  0.65      \n",
      "Data/display_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data         0.65      \n",
      "Data/display_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                     0.61      \n",
      "Data/eyesight-issues_amazon_kindle.txt.data  vs  Data/features_windows7.txt.data                    0.62      \n"
     ]
    }
   ],
   "source": [
    "def main_jacardSimilarity_shingling():\n",
    "    path_to_data = \"Data/\"\n",
    "    shingle_doc = {}\n",
    "    doc_names = []\n",
    "    k = 2\n",
    "    \n",
    "    for documents in os.listdir(path_to_data):\n",
    "        doc_path = path_to_data + str(documents)\n",
    "        doc_names.append(doc_path)\n",
    "        doc_shingle = Shinling(doc_path, k)\n",
    "        d,name = doc_shingle.CreateHash()\n",
    "        shingle_doc[name] = d\n",
    "    \n",
    "    jacard_similarity = Jacard_Similarity()\n",
    "    Score = jacard_similarity.jacard_similarity(shingle_doc,doc_names)\n",
    "    \n",
    "    format = \"{:<100}{:<10}\"    \n",
    "    print( format.format(\"Documents\",\"Score\"))\n",
    "    for Doc,score in Score.items():\n",
    "        score = (\"%.2f\" % score)\n",
    "        print (format.format(Doc,score))\n",
    "    \n",
    "main_jacardSimilarity_shingling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of signature similarities\n",
    "\n",
    "You can run the code by pressing run or ctrl+enter\n",
    " <br> You can change the shingle size by changing the variable __k__, and the number of hash fucntions by changing nrHashFunc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents                                                                                           Score     \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/bathroom_bestwestern_hotel_sfo.txt.data       0.62      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/battery-life_ipod_nano_8gb.txt.data           0.61      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data          0.53      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/comfort_honda_accord_2008.txt.data            0.62      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data            0.58      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data      0.70      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data         0.60      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data        0.69      \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                    0.58      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/battery-life_ipod_nano_8gb.txt.data          0.57      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data         0.50      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/comfort_honda_accord_2008.txt.data           0.58      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data           0.63      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data     0.68      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data        0.59      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data       0.67      \n",
      "Data/bathroom_bestwestern_hotel_sfo.txt.data  vs  Data/features_windows7.txt.data                   0.64      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/battery-life_netbook_1005ha.txt.data             0.44      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/comfort_honda_accord_2008.txt.data               0.50      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data               0.54      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data         0.51      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data            0.49      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data           0.60      \n",
      "Data/battery-life_ipod_nano_8gb.txt.data  vs  Data/features_windows7.txt.data                       0.56      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/comfort_honda_accord_2008.txt.data              0.61      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data              0.57      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data        0.58      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data           0.50      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data          0.53      \n",
      "Data/battery-life_netbook_1005ha.txt.data  vs  Data/features_windows7.txt.data                      0.52      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/comfort_toyota_camry_2007.txt.data                0.77      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data          0.62      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data             0.49      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data            0.64      \n",
      "Data/comfort_honda_accord_2008.txt.data  vs  Data/features_windows7.txt.data                        0.62      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/directions_garmin_nuvi_255W_gps.txt.data          0.66      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data             0.55      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data            0.69      \n",
      "Data/comfort_toyota_camry_2007.txt.data  vs  Data/features_windows7.txt.data                        0.70      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/display_garmin_nuvi_255W_gps.txt.data       0.62      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data      0.71      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                  0.62      \n",
      "Data/display_garmin_nuvi_255W_gps.txt.data  vs  Data/eyesight-issues_amazon_kindle.txt.data         0.61      \n",
      "Data/display_garmin_nuvi_255W_gps.txt.data  vs  Data/features_windows7.txt.data                     0.51      \n",
      "Data/eyesight-issues_amazon_kindle.txt.data  vs  Data/features_windows7.txt.data                    0.68      \n"
     ]
    }
   ],
   "source": [
    "def main_minHashing_similarity():\n",
    "    path_to_data = \"Data/\"\n",
    "    shingle_doc = {}\n",
    "    doc_names = []\n",
    "    k = 2\n",
    "    nrHashFunc = 100\n",
    "    \n",
    "    for documents in os.listdir(path_to_data):\n",
    "        doc_path = path_to_data + str(documents)\n",
    "        doc_names.append(doc_path)\n",
    "        doc_shingle = Shinling(doc_path, k)\n",
    "        d,name = doc_shingle.CreateHash()\n",
    "        shingle_doc[name] = d\n",
    "    \n",
    "    UniversalSet = set()\n",
    "    for i in shingle_doc:\n",
    "        UniversalSet = UniversalSet.union(shingle_doc[i])\n",
    "    \n",
    "    minHashing = minHash(shingle_doc,UniversalSet,nrHashFunc)\n",
    "    CharM = minHashing.createCharMatrix()\n",
    "    signature_matrix = minHashing.SignatureMatrix()\n",
    "    \n",
    "    compare_signatures = CompareSignatures()\n",
    "    similarityScore_signature = compare_signatures.similarity_of_sign(signature_matrix,doc_names) \n",
    "    \n",
    "    format = \"{:<100}{:<10}\"    \n",
    "    print( format.format(\"Documents\",\"Score\"))\n",
    "    for Doc,score in similarityScore_signature.items():\n",
    "        score = (\"%.2f\" % score)\n",
    "        print (format.format(Doc,score))\n",
    "main_minHashing_similarity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of LSH similarity \n",
    "\n",
    "You can run the code by pressing run or ctrl+enter\n",
    " <br> You can change the shingle size by changing the variable __k__, and the number of hash fucntions by changing nrHashFunc.<br> \n",
    "Band size can be adjusted by changing r, consider that the band size is equal to $\\frac{nrHashFunc}{r}$<br>\n",
    "The threshold of the similarity score for the candidate pairs can be adjusted by changing the threshold variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bucket 0': None, 'Bucket 1': None, 'Bucket 2': None, 'Bucket 3': None, 'Bucket 4': None, 'Bucket 5': None, 'Bucket 6': None, 'Bucket 7': None, 'Bucket 8': None, 'Bucket 9': None, 'Bucket 10': None, 'Bucket 11': None, 'Bucket 12': None, 'Bucket 13': None, 'Bucket 14': None, 'Bucket 15': None, 'Bucket 16': None, 'Bucket 17': None, 'Bucket 18': [0, 1], 'Bucket 19': None, 'Bucket 20': None, 'Bucket 21': None, 'Bucket 22': None, 'Bucket 23': None, 'Bucket 24': [0, 1]}\n",
      "Documents                                                                                           Score     \n",
      "Data/accuracy_garmin_nuvi_255W_gps.txt.data vs Data/bathroom_bestwestern_hotel_sfo.txt.data         0.62      \n",
      "--- 0.2812483310699463 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def main_LSH_similarity(n_documents):\n",
    "    path_to_data = \"Data/\"\n",
    "    \n",
    "    k = 2\n",
    "    nrHashFunc = 100\n",
    "    r = 4\n",
    "    threshold = 0.4\n",
    "    \n",
    "    shingle_doc = {}\n",
    "    doc_names = []\n",
    "    \n",
    "    for index, documents in enumerate(os.listdir(path_to_data)):\n",
    "        if index < n_documents and len(os.listdir(path_to_data)) >= n_documents:\n",
    "            \n",
    "            doc_path = path_to_data + str(documents)\n",
    "            doc_names.append(doc_path)\n",
    "            doc_shingle = Shinling(doc_path, k)\n",
    "            d,name = doc_shingle.CreateHash()\n",
    "            shingle_doc[name] = d\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    UniversalSet = set()\n",
    "    for i in shingle_doc:\n",
    "        UniversalSet = UniversalSet.union(shingle_doc[i])\n",
    "    \n",
    "    minHashing = minHash(shingle_doc,UniversalSet,nrHashFunc)\n",
    "    CharM = minHashing.createCharMatrix()\n",
    "    signature_matrix = minHashing.SignatureMatrix()\n",
    "    \n",
    "    lsh = LSH(signature_matrix, r)\n",
    "    similarityScore_LSH = lsh.SimilarDocuments(doc_names,threshold)\n",
    "\n",
    "\n",
    "    format = \"{:<100}{:<10}\"    \n",
    "    print( format.format(\"Documents\",\"Score\"))\n",
    "    for Doc,Score in similarityScore_LSH.items():\n",
    "        score = (\"%.2f\" % Score)\n",
    "        print (format.format(Doc,Score))\n",
    "        \n",
    "start_time = time.time()\n",
    "main_LSH_similarity(2)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding similar documents in a corpus of 5-10 documents. Testing for time versus input size with a treshold t = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents                                                                                           Score     \n",
      "Time: 0.703045129776001 seconds \n",
      "Input size: 5 documents\n",
      "---------------------------------------\n",
      "Documents                                                                                           Score     \n",
      "Time: 0.7812490463256836 seconds \n",
      "Input size: 6 documents\n",
      "---------------------------------------\n",
      "Documents                                                                                           Score     \n",
      "Data/comfort_honda_accord_2008.txt.data vs Data/comfort_toyota_camry_2007.txt.data                  0.72      \n",
      "Time: 0.8906242847442627 seconds \n",
      "Input size: 7 documents\n",
      "---------------------------------------\n",
      "Documents                                                                                           Score     \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data vs Data/display_garmin_nuvi_255W_gps.txt.data         0.7       \n",
      "Time: 0.9843931198120117 seconds \n",
      "Input size: 8 documents\n",
      "---------------------------------------\n",
      "Documents                                                                                           Score     \n",
      "Time: 1.0624995231628418 seconds \n",
      "Input size: 9 documents\n",
      "---------------------------------------\n",
      "Documents                                                                                           Score     \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data vs Data/display_garmin_nuvi_255W_gps.txt.data         0.77      \n",
      "Data/directions_garmin_nuvi_255W_gps.txt.data vs Data/eyesight-issues_amazon_kindle.txt.data        0.71      \n",
      "Time: 1.2656304836273193 seconds \n",
      "Input size: 10 documents\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,11):\n",
    "    start_time = time.time()\n",
    "    main_LSH_similarity(i)\n",
    "    print(\"Time: %s seconds \" %(time.time() - start_time))\n",
    "    print(\"Input size: \" + str(i) + \" documents\" )\n",
    "    print(\"---------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
